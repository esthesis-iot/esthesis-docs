{"objectID":"_influxdb_writer.html#inputs","parent":"_influxdb_writer.html#data_types","pageViews":0,"url":"writerside-documentation/influxdb-writer.html#inputs","mainTitle":"InfluxDB Writer dataflow","product":"","headings":"InfluxDB Writer dataflow,Inputs","content":"- InfluxDB: The DFL requires the connection details to the InfluxDB database, including the URL, an access token, and the number of the bucket to write to. - Kafka: The DFL obtains telemetry and metadata from Kafka. It requires Kafka connection details, as well as the topic names from which to read metadata and telemetry. You may leave empty either of those, if you do not need to process telemetry or metadata respectively. - Kubernetes: The DFL is deployed as a Kubernetes deployment and requires the Kubernetes connection details. - Concurrency: You can set the number of messages the DFL can locally queue for processing, the polling frequency, as well as the number of parallel execution processing threads. - Logging: You can specify the logging level for the esthesis components in this DFL, as well as the general logging level. ","pageTitle":"Inputs","metaDescription":"","type":"Documentation","breadcrumbs":"Dataflows","root":0,"depth":1}