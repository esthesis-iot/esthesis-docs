{"objectID":"_rdbms_writer.html#inputs","parent":"_rdbms_writer.html#data_storage_strategy","pageViews":0,"url":"writerside-documentation/rdbms-writer.html#inputs","mainTitle":"RDBMS Writer DFL","product":"","headings":"RDBMS Writer DFL,Inputs","content":"- RDBMS: The DFL requires the connection details to the RDBMS database, including the URL, the username, the password, and the database name. - Kafka: The DFL obtains telemetry and metadata from Kafka. It requires Kafka connection details, as well as the topic names from which to read metadata and telemetry. You may leave empty either of those, if you do not need to process telemetry or metadata respectively. - Kubernetes: The DFL is deployed as a Kubernetes deployment and requires the Kubernetes connection details. - Concurrency: You can set the number of messages the DFL can locally queue for processing, the polling frequency, as well as the number of parallel execution processing threads. - Logging: You can specify the logging level for the esthesis components in this DFL, as well as the general logging level. ","pageTitle":"Inputs","metaDescription":"","type":"Documentation","breadcrumbs":"Dataflows","root":0,"depth":1}